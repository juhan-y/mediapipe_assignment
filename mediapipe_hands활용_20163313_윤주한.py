# -*- coding: utf-8 -*-
"""mediapipe_hands활용_20163313_윤주한

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NMwR42akhjin7VCTRWms6LZPg053_Ksy

Usage example of MediaPipe Hands Solution API in Python (see also http://solutions.mediapipe.dev/hands).
"""

!pip install mediapipe

"""Upload any image that contains hand(s) to the Colab. We took two examples from the web: https://unsplash.com/photos/QyCH5jwrD_A and https://unsplash.com/photos/tSePVHkxUCk

"""

from google.colab import drive
drive.mount('/content/drive')

"""All MediaPipe Solutions Python API examples are under mp.solutions.

For the MediaPipe Hands solution, we can access this module as `mp_hands = mp.solutions.hands`.

You may change the parameters, such as `static_image_mode`, `max_num_hands`, and `min_detection_confidence`, during the initialization. Run `help(mp_hands.Hands)` to get more informations about the parameters.
"""

import mediapipe as mp
mp_hands = mp.solutions.hands

help(mp_hands.Hands)

import os.path as ops
import numpy as np
import torch
import cv2
import time
import os
import matplotlib.pylab as plt
import sys

from google.colab.patches import cv2_imshow
mp_drawing = mp.solutions.drawing_utils 

cap = cv2.VideoCapture('/content/drive/MyDrive/driving_motions1.mp4')
     
if (cap.isOpened()== False): 
    print("Error opening video stream or file")
  
cnt = 0
count = 0
while(cap.isOpened()):
    
    ret, frame = cap.read()
    if ret == True:
      cv2.waitKey(100)

      with mp_hands.Hands(
          static_image_mode=True,
          max_num_hands=2,
          min_detection_confidence=0.7) as hands:
        
          results = hands.process(cv2.flip(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), 1))
          image_hight, image_width, _ = frame.shape
          
          
          print(results.multi_handedness)

          annotated_image = cv2.flip(frame.copy(), 1)

          OUTPUT_IMAGE_PATH = os.path.join('/content/drive/MyDrive/hands_folder', 'image_%09d.jpg' % (cnt))
          print("Now %d-th images being processed..." % (cnt))

          if(results.multi_handedness == None):
            if(count==0):
              start_time = time.time()
              count+=1

            end_time = time.time()

            process_time = end_time - start_time

            
            if(process_time >= 2):
              print("Warning message generate")
              font = cv2.FONT_HERSHEY_DUPLEX                                                      
              cv2.putText(annotated_image, "Warning!!", (250, 250), font, 2,(0,0,155), 2, cv2.LINE_AA)  
            
          else:
            count = 0
            for hand_landmarks in results.multi_hand_landmarks: 
              mp_drawing.draw_landmarks(
                annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(annotated_image, "Safe!!", (250, 250), font, 2,(0,0,155), 2, cv2.LINE_AA)

          plt.imsave(OUTPUT_IMAGE_PATH, annotated_image)
          
    else: 
      break
              
    cnt += 1
  
cap.release()

try:
    if(os.path.isdir('/content/drive/MyDrive/hands_folder')):
        for root, dirs, files in os.walk('/content/drive/MyDrive/hands_folder', topdown=False):
            
            bIsFirst = True
            for name in files:
                cur_file = os.path.join('/content/drive/MyDrive/hands_folder', name)
                cur_img = cv2.imread(cur_file)
                
                print("Currently %s being processed..." % (cur_file))
            
                
                if (type(cur_img) == np.ndarray):
                    if (bIsFirst):
                        frame_height = cur_img.shape[0]
                        frame_width = cur_img.shape[1]
                         
                        video_file = os.path.join('/content/drive/MyDrive/hands_folder_video','test_video.mp4')
                        out = cv2.VideoWriter(video_file, cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), 10, (frame_width, frame_height))
                    
                    out.write(cur_img)
                    print("success!")
                
                bIsFirst = False
                
except OSError as e:
    if e.errno != errno.EEXIST:
        raise

out.release()

